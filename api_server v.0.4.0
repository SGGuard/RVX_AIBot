import os
import logging
import json
import re
import hashlib
import asyncio
import sys
from typing import Optional, Any, Dict, List
from contextlib import asynccontextmanager
from datetime import datetime, timedelta
from collections import defaultdict

from fastapi import FastAPI, HTTPException, Request, status, Depends, Header
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
from pydantic import BaseModel, Field, validator
from dotenv import load_dotenv
from starlette.concurrency import run_in_threadpool
from tenacity import retry, stop_after_attempt, wait_exponential, RetryError

from google import genai
from google.genai.errors import APIError

# =============================================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ò –ù–ê–°–¢–†–û–ô–ö–ê
# =============================================================================

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler('api_server.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("RVX_API")

load_dotenv()

# –û—Å–Ω–æ–≤–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
MAX_TEXT_LENGTH = int(os.getenv("MAX_TEXT_LENGTH", "4096"))
GEMINI_MODEL = os.getenv("GEMINI_MODEL", "models/gemini-2.5-flash")
GEMINI_TEMPERATURE = float(os.getenv("GEMINI_TEMPERATURE", "0.3"))
GEMINI_MAX_TOKENS = int(os.getenv("GEMINI_MAX_TOKENS", "1500"))
GEMINI_TIMEOUT = int(os.getenv("GEMINI_TIMEOUT", "30"))

# –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ
CACHE_ENABLED = os.getenv("CACHE_ENABLED", "true").lower() == "true"
CACHE_MAX_SIZE = int(os.getenv("CACHE_MAX_SIZE", "1000"))
CACHE_TTL_HOURS = int(os.getenv("CACHE_TTL_HOURS", "24"))

# –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
ALLOWED_ORIGINS = os.getenv("ALLOWED_ORIGINS", "*").split(",")
API_KEY = os.getenv("API_KEY", "")
RATE_LIMIT_PER_MINUTE = int(os.getenv("RATE_LIMIT_PER_MINUTE", "60"))

# –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
ENABLE_METRICS = os.getenv("ENABLE_METRICS", "true").lower() == "true"
ENABLE_DETAILED_LOGGING = os.getenv("ENABLE_DETAILED_LOGGING", "false").lower() == "true"

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
client: Optional[genai.Client] = None
request_counter = {
    "total": 0,
    "success": 0,
    "errors": 0,
    "fallback": 0,
    "cached": 0
}
response_cache: Dict[str, Dict] = {}
rate_limit_tracker: Dict[str, List[datetime]] = defaultdict(list)
processing_times: List[float] = []  # –î–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Å—Ä–µ–¥–Ω–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏

# =============================================================================
# –ú–û–î–ï–õ–ò –î–ê–ù–ù–´–•
# =============================================================================

class NewsPayload(BaseModel):
    """–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–∏."""
    text_content: str = Field(
        ...,
        min_length=10,
        max_length=MAX_TEXT_LENGTH,
        description="–¢–µ–∫—Å—Ç –∫—Ä–∏–ø—Ç–æ–Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"
    )
    
    @validator('text_content')
    def validate_and_sanitize(cls, v):
        if not v.strip():
            raise ValueError("–¢–µ–∫—Å—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
        sanitized = sanitize_input(v.strip())
        if len(sanitized) < 10:
            raise ValueError("–¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏")
        return sanitized

class SimplifiedResponse(BaseModel):
    """–û—Ç–≤–µ—Ç API —Å –∞–Ω–∞–ª–∏–∑–æ–º."""
    simplified_text: str = Field(..., description="–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–∏")
    cached: bool = Field(default=False, description="–ü–æ–ª—É—á–µ–Ω –∏–∑ –∫—ç—à–∞")
    processing_time_ms: Optional[float] = Field(None, description="–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö")
    model_used: Optional[str] = Field(None, description="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å AI")

class HealthResponse(BaseModel):
    """–°—Ç–∞—Ç—É—Å –∑–¥–æ—Ä–æ–≤—å—è API."""
    status: str = Field(..., description="healthy, degraded –∏–ª–∏ down")
    gemini_available: bool
    requests_total: int
    requests_success: int
    requests_errors: int
    requests_fallback: int
    requests_cached: int
    cache_size: int
    cache_hit_rate: float = Field(..., description="–ü—Ä–æ—Ü–µ–Ω—Ç –ø–æ–ø–∞–¥–∞–Ω–∏–π –≤ –∫—ç—à")
    uptime_seconds: Optional[float] = None
    memory_usage_mb: Optional[float] = None

class MetricsResponse(BaseModel):
    """–î–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ API."""
    uptime_seconds: float
    total_requests: int
    success_rate: float
    error_rate: float
    fallback_rate: float
    cache_hit_rate: float
    avg_processing_time_ms: float
    cache_stats: Dict[str, Any]

class ClearCacheResponse(BaseModel):
    """–û—Ç–≤–µ—Ç –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –∫—ç—à–∞."""
    success: bool
    cleared_entries: int
    message: str

# =============================================================================
# –£–¢–ò–õ–ò–¢–´ –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò
# =============================================================================

def sanitize_input(text: str) -> str:
    """–ó–∞—â–∏—Ç–∞ –æ—Ç prompt injection –∏ –æ—á–∏—Å—Ç–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."""
    dangerous_patterns = [
        r'ignore\s+(previous|all|above)\s+instructions?',
        r'system\s*:',
        r'<\|im_start\|>',
        r'<\|im_end\|>',
        r'you\s+are\s+now',
        r'forget\s+everything',
        r'new\s+instructions?',
        r'act\s+as',
        r'pretend\s+to\s+be',
    ]
    
    cleaned = text
    for pattern in dangerous_patterns:
        cleaned = re.sub(pattern, '', cleaned, flags=re.IGNORECASE)
    
    # –£–¥–∞–ª—è–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –æ–ø–∞—Å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
    cleaned = re.sub(r'[^\w\s\d\.,!?;:()\-‚Äî\'\"‚Ññ@#$%&*+=/\\<>¬´¬ª‚Ç¨¬£¬•‚ÇΩ‚Çø\n]', '', cleaned)
    
    return cleaned[:MAX_TEXT_LENGTH]

async def verify_api_key(x_api_key: Optional[str] = Header(None)) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ API –∫–ª—é—á–∞ –µ—Å–ª–∏ –æ–Ω –Ω–∞—Å—Ç—Ä–æ–µ–Ω."""
    if not API_KEY:
        return True
    
    if x_api_key != API_KEY:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="–ù–µ–≤–µ—Ä–Ω—ã–π API –∫–ª—é—á"
        )
    return True

async def check_rate_limit(request: Request):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ rate limiting –ø–æ IP."""
    client_ip = request.client.host
    now = datetime.now()
    
    # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏
    rate_limit_tracker[client_ip] = [
        timestamp for timestamp in rate_limit_tracker[client_ip]
        if now - timestamp < timedelta(minutes=1)
    ]
    
    if len(rate_limit_tracker[client_ip]) >= RATE_LIMIT_PER_MINUTE:
        raise HTTPException(
            status_code=status.HTTP_429_TOO_MANY_REQUESTS,
            detail=f"–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ ({RATE_LIMIT_PER_MINUTE}/–º–∏–Ω)"
        )
    
    rate_limit_tracker[client_ip].append(now)

# =============================================================================
# –£–¢–ò–õ–ò–¢–´ –ö–≠–®–ò–†–û–í–ê–ù–ò–Ø
# =============================================================================

def hash_text(text: str) -> str:
    """–°–æ–∑–¥–∞–µ—Ç SHA-256 —Ö–µ—à –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è."""
    normalized = text.lower().strip()
    return hashlib.sha256(normalized.encode('utf-8')).hexdigest()

def get_from_cache(cache_key: str) -> Optional[str]:
    """–ü–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç –∏–∑ –∫—ç—à–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π TTL."""
    if not CACHE_ENABLED or cache_key not in response_cache:
        return None
    
    cached = response_cache[cache_key]
    cached_time = datetime.fromisoformat(cached["timestamp"])
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º TTL
    if datetime.utcnow() - cached_time > timedelta(hours=CACHE_TTL_HOURS):
        del response_cache[cache_key]
        logger.info(f"üóëÔ∏è –ö—ç—à –∏—Å—Ç–µ–∫ –¥–ª—è {cache_key[:8]}")
        return None
    
    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫
    cached["hits"] += 1
    cached["last_used"] = datetime.utcnow().isoformat()
    
    return cached["text"]

def save_to_cache(cache_key: str, text: str):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç–≤–µ—Ç –≤ –∫—ç—à —Å LRU eviction."""
    if not CACHE_ENABLED:
        return
    
    # LRU eviction
    if len(response_cache) >= CACHE_MAX_SIZE:
        lru_key = min(
            response_cache.keys(),
            key=lambda k: (
                response_cache[k].get("hits", 0),
                response_cache[k].get("last_used", "")
            )
        )
        del response_cache[lru_key]
        logger.info(f"üóëÔ∏è LRU eviction: {lru_key[:8]}")
    
    response_cache[cache_key] = {
        "text": text,
        "timestamp": datetime.utcnow().isoformat(),
        "last_used": datetime.utcnow().isoformat(),
        "hits": 0
    }

def clear_cache(max_age_hours: Optional[int] = None) -> int:
    """–û—á–∏—â–∞–µ—Ç –∫—ç—à."""
    if max_age_hours is None:
        cleared = len(response_cache)
        response_cache.clear()
        return cleared
    
    now = datetime.utcnow()
    to_delete = []
    
    for key, cached in response_cache.items():
        cached_time = datetime.fromisoformat(cached["timestamp"])
        if now - cached_time > timedelta(hours=max_age_hours):
            to_delete.append(key)
    
    for key in to_delete:
        del response_cache[key]
    
    return len(to_delete)

# =============================================================================
# –£–¢–ò–õ–ò–¢–´ –¢–ï–ö–°–¢–ê
# =============================================================================

def clean_text(text: str) -> str:
    """–£–¥–∞–ª—è–µ—Ç markdown, HTML-—Ç–µ–≥–∏ –∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã."""
    if not text:
        return ""
    
    text = re.sub(r'<[^>]*>', '', text)
    text = re.sub(r'(\*\*|__|\*|_|~~|`)', '', text)
    text = ' '.join(text.split())
    
    return text.strip()

def extract_json_from_response(raw_text: str) -> Optional[dict]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ AI."""
    if not raw_text:
        return None
    
    text = re.sub(r'```json\s*', '', raw_text, flags=re.IGNORECASE).strip()
    text = re.sub(r'```\s*', '', text).strip()
    
    xml_match = re.search(r'<json>(.*?)</json>', text, re.DOTALL | re.IGNORECASE)
    if xml_match:
        text_to_parse = xml_match.group(1).strip()
    else:
        brace_match = re.search(r'\{.*\}', text, re.DOTALL)
        if brace_match:
            text_to_parse = brace_match.group(0)
        else:
            if ENABLE_DETAILED_LOGGING:
                logger.warning(f"JSON –Ω–µ –Ω–∞–π–¥–µ–Ω: {raw_text[:200]}...")
            return None
    
    try:
        data = json.loads(text_to_parse)
        return data if isinstance(data, dict) else None
    except json.JSONDecodeError as e:
        logger.error(f"JSON decode error: —Å—Ç—Ä–æ–∫–∞ {e.lineno}, –∫–æ–ª–æ–Ω–∫–∞ {e.colno}")
        if ENABLE_DETAILED_LOGGING:
            logger.debug(f"–¢–µ–∫—Å—Ç: {text_to_parse[:300]}")
        return None

def validate_analysis(data: Any) -> tuple[bool, Optional[str]]:
    """–í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –æ—Ç–≤–µ—Ç–∞ AI."""
    if not isinstance(data, dict):
        return False, "–û—Ç–≤–µ—Ç –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º"
    
    required_fields = ["summary_text", "impact_points"]
    for field in required_fields:
        if field not in data:
            return False, f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ: {field}"
    
    summary = data["summary_text"]
    if not isinstance(summary, str):
        return False, "summary_text –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π"
    
    summary_len = len(summary.strip())
    if summary_len < 20:
        return False, f"summary_text —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π ({summary_len} —Å–∏–º–≤–æ–ª–æ–≤)"
    if summary_len > 1000:
        return False, f"summary_text —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π ({summary_len} —Å–∏–º–≤–æ–ª–æ–≤)"
    
    points = data["impact_points"]
    if not isinstance(points, list):
        return False, "impact_points –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º"
    
    points_count = len(points)
    if points_count < 2:
        return False, f"–ú–∏–Ω–∏–º—É–º 2 impact_points (–ø–æ–ª—É—á–µ–Ω–æ {points_count})"
    if points_count > 10:
        return False, f"–ú–∞–∫—Å–∏–º—É–º 10 impact_points (–ø–æ–ª—É—á–µ–Ω–æ {points_count})"
    
    for i, point in enumerate(points):
        if not isinstance(point, str):
            return False, f"impact_points[{i}] –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π"
        point_len = len(point.strip())
        if point_len < 10:
            return False, f"impact_points[{i}] —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π ({point_len} —Å–∏–º–≤–æ–ª–æ–≤)"
        if point_len > 500:
            return False, f"impact_points[{i}] —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π ({point_len} —Å–∏–º–≤–æ–ª–æ–≤)"
    
    return True, None

def format_response(analysis: dict) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∞–Ω–∞–ª–∏–∑."""
    summary = clean_text(analysis.get('summary_text', '–ù–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è'))
    
    emojis = ['üìâ', 'üìä', '‚ö°Ô∏è', 'üí∞', 'üéØ', 'üî•', 'üìà', '‚ö†Ô∏è', 'üí°', 'üåê']
    separator = "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
    
    result = f"{separator}\nüîç –°–£–¢–¨\n\n{summary}\n\n{separator}\nüí° –í–õ–ò–Ø–ù–ò–ï –ù–ê –ö–†–ò–ü–¢–£\n\n"
    
    for i, point in enumerate(analysis.get('impact_points', [])):
        if point.strip():
            clean_point = clean_text(point)
            emoji = emojis[i % len(emojis)]
            result += f"{emoji} {clean_point}\n\n"
    
    result += separator
    return result.strip()

def fallback_analysis(text: str) -> str:
    """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –±–µ–∑ AI."""
    keywords = {
        'bitcoin': '‚Çø', 'btc': '‚Çø', 'ethereum': 'Œû', 'eth': 'Œû',
        'sec': '‚öñÔ∏è', '—Ä–µ–≥—É–ª—è—Ç–æ—Ä': '‚öñÔ∏è', 'regulation': '‚öñÔ∏è',
        'hack': 'üö®', '–≤–∑–ª–æ–º': 'üö®', 'breach': 'üö®',
        'dump': 'üìâ', '–æ–±–≤–∞–ª': 'üìâ', 'crash': 'üìâ',
        'pump': 'üìà', '—Ä–æ—Å—Ç': 'üìà', 'surge': 'üìà',
        'etf': 'üíº', 'whale': 'üêã', 'fomo': 'üöÄ',
        'bear': 'üêª', 'bull': 'üêÇ', 'halving': '‚ö°'
    }
    
    text_lower = text.lower()
    summary = text[:300] + "..." if len(text) > 300 else text
    
    impact = "‚ö†Ô∏è AI –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑:\n\n"
    
    found_keywords = []
    for word, emoji in keywords.items():
        if word in text_lower:
            found_keywords.append(f"{emoji} –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ: {word.upper()}")
    
    if found_keywords:
        impact += '\n'.join(found_keywords[:5])
    else:
        impact += "üì∞ –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –∫—Ä–∏–ø—Ç–æ–Ω–æ–≤–æ—Å—Ç—å"
    
    separator = "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
    return f"ü§ñ –£–ü–†–û–©–ï–ù–ù–´–ô –†–ï–ñ–ò–ú\n\n{separator}\n{summary}\n\n{separator}\n{impact}"

# =============================================================================
# GEMINI API
# =============================================================================

def build_gemini_config() -> dict:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è Gemini."""
    system_prompt = (
        "–¢—ã ‚Äî **RVX Crypto Analyst**, AI-–∞–Ω–∞–ª–∏—Ç–∏–∫ –∫—Ä–∏–ø—Ç–æ–Ω–æ–≤–æ—Å—Ç–µ–π. "
        "–û–±—ä—è—Å–Ω—è–π —Å–ª–æ–∂–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º.\n\n"
        
        "**–°–¢–ò–õ–¨:**\n"
        "- –î—Ä—É–∂–µ–ª—é–±–Ω—ã–π, —É–≤–µ—Ä–µ–Ω–Ω—ã–π —Ç–æ–Ω\n"
        "- –§–æ–∫—É—Å –Ω–∞ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –≤–ª–∏—è–Ω–∏–µ\n"
        "- –î–ª—è –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç—Ä–µ–π–¥–µ—Ä–æ–≤\n"
        "- –ë–µ–∑ —Å–ª–æ–∂–Ω–æ–≥–æ –∂–∞—Ä–≥–æ–Ω–∞\n\n"
        
        "**–ü–†–ê–í–ò–õ–ê:**\n"
        "1. –¢–æ–ª—å–∫–æ JSON –≤ —Ç–µ–≥–∞—Ö <json></json>\n"
        "2. –ó–∞–ø—Ä–µ—â–µ–Ω–æ: Markdown, —ç–º–æ–¥–∑–∏, HTML\n"
        "3. –¢–æ–ª—å–∫–æ –ø—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç\n\n"
        
        "**–§–û–†–ú–ê–¢:**\n"
        '{"summary_text": "2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –æ —Å—É—Ç–∏", '
        '"impact_points": ["–í–ª–∏—è–Ω–∏–µ 1", "–í–ª–∏—è–Ω–∏–µ 2", "–í–ª–∏—è–Ω–∏–µ 3"]}\n\n'
        
        "**–ü–†–ò–ú–ï–†:**\n"
        '<json>{"summary_text": "SEC –æ–¥–æ–±—Ä–∏–ª–∞ –±–∏—Ç–∫–æ–∏–Ω-ETF –æ—Ç BlackRock. '
        '–ò–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–∞–ª—ã –º–æ–≥—É—Ç –ø–æ–∫—É–ø–∞—Ç—å BTC —á–µ—Ä–µ–∑ –±—Ä–æ–∫–µ—Ä–æ–≤.", '
        '"impact_points": ["–ü—Ä–∏—Ç–æ–∫ 50-100 –º–ª—Ä–¥ –∑–∞ –≥–æ–¥, —Ä–æ—Å—Ç BTC –Ω–∞ 30-50%", '
        '"–õ–µ–≥–∏—Ç–∏–º–Ω–æ—Å—Ç—å –∫—Ä–∏–ø—Ç—ã —Ä–∞—Å—Ç–µ—Ç", '
        '"–î—Ä—É–≥–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏ –ø–æ–¥–∞–¥—É—Ç –∑–∞—è–≤–∫–∏"]}</json>'
    )
    
    return {
        "system_instruction": system_prompt,
        "temperature": GEMINI_TEMPERATURE,
        "max_output_tokens": GEMINI_MAX_TOKENS,
        "top_p": 0.95,
        "top_k": 40
    }

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10),
    reraise=True
)
async def call_gemini_with_retry(
    client: genai.Client,
    model: str,
    contents: list,
    config: dict
) -> Any:
    """–í—ã–∑–æ–≤ Gemini —Å retry."""
    def sync_call():
        return client.models.generate_content(
            model=model,
            contents=contents,
            config=config
        )
    
    return await asyncio.wait_for(
        run_in_threadpool(sync_call),
        timeout=GEMINI_TIMEOUT
    )

# =============================================================================
# LIFECYCLE
# =============================================================================

start_time = datetime.utcnow()

@asynccontextmanager
async def lifespan(app: FastAPI):
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º."""
    global client
    
    logger.info("=" * 70)
    logger.info("üöÄ RVX AI Backend API v4.0")
    logger.info("=" * 70)
    
    if not GEMINI_API_KEY:
        logger.critical("‚ùå GEMINI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω!")
    else:
        try:
            client = genai.Client(api_key=GEMINI_API_KEY)
            logger.info("‚úÖ Gemini initialized")
        except Exception as e:
            logger.error(f"‚ùå Gemini error: {e}")
            client = None
    
    logger.info("üìã Config:")
    logger.info(f"  ‚Ä¢ Model: {GEMINI_MODEL}")
    logger.info(f"  ‚Ä¢ Max length: {MAX_TEXT_LENGTH}")
    logger.info(f"  ‚Ä¢ Cache: {'ON' if CACHE_ENABLED else 'OFF'}")
    logger.info(f"  ‚Ä¢ Rate limit: {RATE_LIMIT_PER_MINUTE}/min")
    logger.info("=" * 70)
    
    yield
    
    logger.info("üõë Shutdown")
    logger.info(f"üìä Stats: {request_counter}")

# =============================================================================
# APP
# =============================================================================

app = FastAPI(
    title="RVX AI Backend",
    version="4.0.0",
    description="Production API –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫—Ä–∏–ø—Ç–æ–Ω–æ–≤–æ—Å—Ç–µ–π",
    lifespan=lifespan
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["GET", "POST", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)

app.add_middleware(GZipMiddleware, minimum_size=1000)

@app.middleware("http")
async def log_requests(request: Request, call_next):
    """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤."""
    start = datetime.utcnow()
    request_counter["total"] += 1
    
    logger.info(f"üì® {request.method} {request.url.path} | {request.client.host}")
    
    try:
        response = await call_next(request)
        duration = (datetime.utcnow() - start).total_seconds()
        
        logger.info(f"‚úÖ {request.url.path} | {response.status_code} | {duration:.3f}s")
        
        response.headers["X-Processing-Time"] = f"{duration:.3f}"
        return response
        
    except Exception as e:
        duration = (datetime.utcnow() - start).total_seconds()
        logger.error(f"‚ùå Error: {e} | {duration:.3f}s")
        request_counter["errors"] += 1
        
        return JSONResponse(
            status_code=500,
            content={
                "simplified_text": "‚ùå –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞",
                "cached": False
            }
        )

# =============================================================================
# ENDPOINTS
# =============================================================================

@app.get("/")
async def root():
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± API."""
    uptime = (datetime.utcnow() - start_time).total_seconds()
    
    return {
        "service": "RVX AI Backend",
        "version": "4.0.0",
        "status": "operational",
        "uptime_seconds": round(uptime, 2),
        "gemini_available": client is not None,
        "endpoints": {
            "analyze": "POST /explain_news",
            "health": "GET /health",
            "metrics": "GET /metrics",
            "cache_clear": "DELETE /cache"
        }
    }

@app.get("/health", response_model=HealthResponse)
async def health_check():
    """Health check."""
    uptime = (datetime.utcnow() - start_time).total_seconds()
    
    total_cache_attempts = request_counter["cached"] + (request_counter["success"] - request_counter["cached"])
    cache_hit_rate = (
        (request_counter["cached"] / total_cache_attempts * 100)
        if total_cache_attempts > 0 else 0.0
    )
    
    memory_mb = sys.getsizeof(response_cache) / (1024 * 1024)
    
    status_value = "healthy" if client else "degraded"
    
    return HealthResponse(
        status=status_value,
        gemini_available=client is not None,
        requests_total=request_counter["total"],
        requests_success=request_counter["success"],
        requests_errors=request_counter["errors"],
        requests_fallback=request_counter["fallback"],
        requests_cached=request_counter["cached"],
        cache_size=len(response_cache),
        cache_hit_rate=round(cache_hit_rate, 2),
        uptime_seconds=round(uptime, 2),
        memory_usage_mb=round(memory_mb, 2)
    )

@app.get("/metrics", response_model=MetricsResponse)
async def get_metrics(api_key_valid: bool = Depends(verify_api_key)):
    """–î–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏."""
    uptime = (datetime.utcnow() - start_time).total_seconds()
    
    total = request_counter["total"]
    success_rate = (request_counter["success"] / total * 100) if total > 0 else 0
    error_rate = (request_counter["errors"] / total * 100) if total > 0 else 0
    fallback_rate = (request_counter["fallback"] / total * 100) if total > 0 else 0
    
    total_cache_attempts = request_counter["cached"] + (request_counter["success"] - request_counter["cached"])
    cache_hit_rate = (
        (request_counter["cached"] / total_cache_attempts * 100)
        if total_cache_attempts > 0 else 0.0
    )
    
    avg_processing = sum(processing_times) / len(processing_times) if processing_times else 0
    
    cache_ages = []
    cache_hits_list = []
    for cached in response_cache.values():
        age = (datetime.utcnow() - datetime.fromisoformat(cached["timestamp"])).total_seconds()
        cache_ages.append(age)
        cache_hits_list.append(cached.get("hits", 0))
    
    return MetricsResponse(
        uptime_seconds=round(uptime, 2),
        total_requests=total,
        success_rate=round(success_rate, 2),
        error_rate=round(error_rate, 2),
        fallback_rate=round(fallback_rate, 2),
        cache_hit_rate=round(cache_hit_rate, 2),
        avg_processing_time_ms=round(avg_processing, 2),
        cache_stats={
            "size": len(response_cache),
            "avg_age_seconds": round(sum(cache_ages) / len(cache_ages), 2) if cache_ages else 0,
            "avg_hits": round(sum(cache_hits_list) / len(cache_hits_list), 2) if cache_hits_list else 0
        }
    )

@app.delete("/cache", response_model=ClearCacheResponse)
async def clear_cache_endpoint(
    max_age_hours: Optional[int] = None,
    api_key_valid: bool = Depends(verify_api_key)
):
    """–û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞."""
    try:
        cleared = clear_cache(max_age_hours)
        
        message = (
            f"–û—á–∏—â–µ–Ω–æ {cleared} –∑–∞–ø–∏—Å–µ–π"
            if max_age_hours
            else f"–í–µ—Å—å –∫—ç—à –æ—á–∏—â–µ–Ω ({cleared} –∑–∞–ø–∏—Å–µ–π)"
        )
        
        logger.info(f"üóëÔ∏è {message}")
        
        return ClearCacheResponse(
            success=True,
            cleared_entries=cleared,
            message=message
        )
    except Exception as e:
        logger.error(f"‚ùå Cache clear error: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∫—ç—à–∞: {str(e)}"
        )

@app.post("/explain_news", response_model=SimplifiedResponse,dependencies=[Depends(check_rate_limit)])
async def explain_news(payload: NewsPayload):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫—Ä–∏–ø—Ç–æ–Ω–æ–≤–æ—Å—Ç—å."""
    start_time_request = datetime.utcnow()
    news_text = payload.text_content
    text_hash = hash_text(news_text)
    
    logger.info(f"üì• Request: {len(news_text)} chars | Hash: {text_hash[:8]}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞
    cached_response = get_from_cache(text_hash)
    if cached_response:
        duration_ms = (datetime.utcnow() - start_time_request).total_seconds() * 1000
        
        logger.info(f"üíæ Cache HIT: {text_hash[:8]}")
        request_counter["success"] += 1
        request_counter["cached"] += 1
        
        return SimplifiedResponse(
            simplified_text=cached_response,
            cached=True,
            processing_time_ms=round(duration_ms, 2),
            model_used="cache"
        )
    
    # Fallback –µ—Å–ª–∏ Gemini –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
    if not client:
