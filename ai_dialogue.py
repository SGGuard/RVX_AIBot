#!/usr/bin/env python3
"""
üöÄ –†–ï–ê–õ–¨–ù–´–ô –ò–ò –î–ò–ê–õ–û–ì v0.24 - GROQ + MISTRAL + GEMINI —Å –ú–ï–¢–†–ò–ö–ê–ú–ò

v0.24 - –ü–æ–ª–Ω–æ—Å—Ç—å—é –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã + –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥:
‚úÖ Groq - PRIMARY (—Å–∞–º—ã–π –±—ã—Å—Ç—Ä—ã–π, 100ms!)
‚úÖ Mistral - FALLBACK 1 (—Ç–æ–∂–µ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π)
‚úÖ Gemini - FALLBACK 2 (20 –∑–∞–ø—Ä–æ—Å–æ–≤/–¥–µ–Ω—å)
‚úÖ –ú–ï–¢–†–ò–ö–ò - –ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤

–ù–ò–ö–ê–ö–ò–• –ü–õ–ê–¢–ï–ñ–ï–ô, –ù–ò–ö–ê–ö–ò–• –õ–ò–ú–ò–¢–û–í!
"""

import httpx
import json
import logging
from typing import Optional, List, Dict, Tuple
import os
from dotenv import load_dotenv
import time
from datetime import datetime

load_dotenv()

logger = logging.getLogger(__name__)

# ==================== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ====================

# Groq (PRIMARY)
GROQ_API_KEY = os.getenv("GROQ_API_KEY", "")
GROQ_MODEL = os.getenv("GROQ_MODEL", "llama-3.3-70b-versatile")
GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"

# Mistral (FALLBACK 1)
MISTRAL_API_KEY = os.getenv("MISTRAL_API_KEY", "")
MISTRAL_MODEL = os.getenv("MISTRAL_MODEL", "mistral-large")
MISTRAL_API_URL = "https://api.mistral.ai/v1/chat/completions"

# Gemini (FALLBACK 2)
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")
GEMINI_MODEL = os.getenv("GEMINI_MODEL", "gemini-2.5-flash").replace("models/", "")
GEMINI_API_BASE = "https://generativelanguage.googleapis.com/v1beta/models"

TIMEOUT = float(os.getenv("GEMINI_TIMEOUT", "15.0"))

# ==================== –ú–ï–¢–†–ò–ö–ò v0.24 ====================

dialogue_metrics = {
    "total_requests": 0,
    "groq_requests": 0,
    "groq_success": 0,
    "groq_errors": 0,
    "groq_timeouts": 0,
    "groq_total_time": 0.0,
    
    "mistral_requests": 0,
    "mistral_success": 0,
    "mistral_errors": 0,
    "mistral_timeouts": 0,
    
    "gemini_requests": 0,
    "gemini_success": 0,
    "gemini_errors": 0,
    "gemini_timeouts": 0,
    
    "total_errors": 0,
    "total_success": 0,
    "avg_response_time": 0.0,
    "last_updated": None
}

logger.info(f"üöÄ AI Dialogue v0.24 (METRICS): GROQ={GROQ_MODEL}, MISTRAL={MISTRAL_MODEL}, GEMINI={GEMINI_MODEL}")


# ==================== –§–£–ù–ö–¶–ò–ò –ú–ï–¢–†–ò–ö ====================

def update_metrics(provider: str, success: bool, response_time: float, error_type: str = None):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞."""
    global dialogue_metrics
    
    dialogue_metrics["total_requests"] += 1
    
    if provider == "groq":
        dialogue_metrics["groq_requests"] += 1
        if success:
            dialogue_metrics["groq_success"] += 1
            dialogue_metrics["groq_total_time"] += response_time
        elif error_type == "timeout":
            dialogue_metrics["groq_timeouts"] += 1
        else:
            dialogue_metrics["groq_errors"] += 1
    
    elif provider == "mistral":
        dialogue_metrics["mistral_requests"] += 1
        if success:
            dialogue_metrics["mistral_success"] += 1
        elif error_type == "timeout":
            dialogue_metrics["mistral_timeouts"] += 1
        else:
            dialogue_metrics["mistral_errors"] += 1
    
    elif provider == "gemini":
        dialogue_metrics["gemini_requests"] += 1
        if success:
            dialogue_metrics["gemini_success"] += 1
        elif error_type == "timeout":
            dialogue_metrics["gemini_timeouts"] += 1
        else:
            dialogue_metrics["gemini_errors"] += 1
    
    if success:
        dialogue_metrics["total_success"] += 1
    else:
        dialogue_metrics["total_errors"] += 1
    
    dialogue_metrics["last_updated"] = datetime.now().isoformat()


def get_metrics_summary() -> Dict:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–≤–æ–¥–∫—É –º–µ—Ç—Ä–∏–∫."""
    summary = {
        "timestamp": dialogue_metrics["last_updated"],
        "total_requests": dialogue_metrics["total_requests"],
        "success_rate": f"{(dialogue_metrics['total_success'] / max(dialogue_metrics['total_requests'], 1) * 100):.1f}%",
        "providers": {
            "groq": {
                "requests": dialogue_metrics["groq_requests"],
                "success": dialogue_metrics["groq_success"],
                "errors": dialogue_metrics["groq_errors"],
                "timeouts": dialogue_metrics["groq_timeouts"],
                "avg_time_ms": f"{(dialogue_metrics['groq_total_time'] / max(dialogue_metrics['groq_success'], 1) * 1000):.0f}"
            },
            "mistral": {
                "requests": dialogue_metrics["mistral_requests"],
                "success": dialogue_metrics["mistral_success"],
                "errors": dialogue_metrics["mistral_errors"],
                "timeouts": dialogue_metrics["mistral_timeouts"]
            },
            "gemini": {
                "requests": dialogue_metrics["gemini_requests"],
                "success": dialogue_metrics["gemini_success"],
                "errors": dialogue_metrics["gemini_errors"],
                "timeouts": dialogue_metrics["gemini_timeouts"]
            }
        }
    }
    return summary



def build_dialogue_system_prompt() -> str:
    """–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –ò–ò."""
    return """–¢—ã - –∫–æ–º–ø–µ—Ç–µ–Ω—Ç–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –≤ —Å—Ñ–µ—Ä–µ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç –∏ –Ω–æ–≤–æ—Å—Ç–µ–π. 
–ü–æ–º–æ–≥–∞–µ—à—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º —Ä–∞–∑–±–∏—Ä–∞—Ç—å—Å—è –≤ –∫—Ä–∏–ø—Ç–µ –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–æ–±—ã—Ç–∏—è.

–û–ë–™–ï–ú –û–¢–í–ï–¢–û–í:
- –û—Ç–≤–µ—á–∞–π –ü–û–î–†–û–ë–ù–û –∏ –ò–ù–§–û–†–ú–ê–¢–ò–í–ù–û (3-5 –∞–±–∑–∞—Ü–µ–≤ –¥–ª—è —Å—Ä–µ–¥–Ω–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞)
- –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å —Ç—Ä–µ–±—É–µ—Ç –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è - –Ω–∞–ø–∏—à–∏ —Å—Ç–æ–ª—å–∫–æ, —Å–∫–æ–ª—å–∫–æ –Ω—É–∂–Ω–æ
- –ù–µ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–π —Å–µ–±—è - –ª—É—á—à–µ –±–æ–ª—å—à–µ –ø–æ–ª–µ–∑–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –æ—Ç–≤–µ—Ç: —Ñ–∞–∫—Ç—ã ‚Üí –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ ‚Üí –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ

–ü–†–ê–í–ò–õ–ê –û–ë–©–ï–ù–ò–Ø:
1. –û—Ç–≤–µ—á–∞–π —è—Å–Ω–æ, –ø–æ —Å—É—â–µ—Å—Ç–≤—É –∏ –ù–ï —Å—ã–ø—å –∫–æ–º–ø–ª–∏–º–µ–Ω—Ç—ã
2. –ù–ï —Ö–≤–∞–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ - —ç—Ç–æ —Ä–∞–∑–¥—Ä–∞–∂–∞–µ—Ç
3. –ë—É–¥—å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º, –∞ –Ω–µ –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–º –ø—Å–µ–≤–¥–æ–º–æ—â–Ω–∏–∫–æ–º
4. –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –†–ï–î–ö–û, —Ç–æ–ª—å–∫–æ –≥–¥–µ —Ä–µ–∞–ª—å–Ω–æ –Ω—É–∂–Ω–æ
5. –û–±—ä—è—Å–Ω—è–π –ø—Ä–æ—Å—Ç–æ –¥–ª—è –Ω–æ–≤–∏—á–∫–æ–≤, –Ω–æ –¥–æ–ø–æ–ª–Ω—è–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏ —Å–ª–æ–∂–Ω—ã–º–∏ –¥–µ—Ç–∞–ª—è–º–∏
6. –£—á–∏—Ç—ã–≤–∞–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
7. –†–∞–∑–≥–æ–≤–æ—Ä–Ω—ã–π —Ç–æ–Ω, –Ω–æ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π
8. –ï—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω - —Å–∫–∞–∂–∏ –ø—Ä—è–º–æ "–Ω–µ –∑–Ω–∞—é" –∏–ª–∏ "–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"
9. –ù–ï –≤—ã–¥—É–º—ã–≤–∞–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –µ—Å–ª–∏ –µ–µ –Ω–µ—Ç
10. –§–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞ –ø–æ–ª–µ–∑–Ω–æ—Å—Ç–∏, –∞ –Ω–µ –Ω–∞ —É—Ç–µ—à–µ–Ω–∏–∏
11. –ü—Ä–∏–≤–æ–¥–∏ –ø—Ä–∏–º–µ—Ä—ã –∏ –∞–Ω–∞–ª–æ–≥–∏–∏ –≥–¥–µ —ç—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç –ø–æ–Ω—è—Ç—å —Ç–µ–º—É
12. –î–∞–π –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ —Ç–µ–æ—Ä–∏—é

–°–¢–ò–õ–¨: –ü–æ–º–æ–≥–∞–π —á–µ—Ä–µ–∑ –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∏ –¥–µ—Ç–∞–ª—è–º–∏."""


def build_context_for_prompt(context_history: List[dict]) -> str:
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏."""
    if not context_history:
        return ""
    
    context_lines = []
    for msg in context_history[-10:]:
        msg_type = msg.get('type', 'user')
        content = msg.get('content', '')[:150]
        if msg_type == 'user':
            context_lines.append(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {content}")
        else:
            context_lines.append(f"–ü–æ–º–æ—â–Ω–∏–∫: {content}")
    
    if context_lines:
        return "–ò–°–¢–û–†–ò–Ø:\n" + "\n".join(context_lines) + "\n\n"
    return ""


def get_ai_response_sync(
    user_message: str,
    context_history: List[dict] = None,
    timeout: float = TIMEOUT
) -> Optional[str]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç –ò–ò —á–µ—Ä–µ–∑ Groq ‚Üí Mistral ‚Üí Gemini
    
    ‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é –±–µ—Å–ø–ª–∞—Ç–Ω–æ
    ‚úÖ –ù–∏–∫–∞–∫–∏—Ö –ª–∏–º–∏—Ç–æ–≤ (rate limit 30 req/min)
    ‚úÖ –ë—ã—Å—Ç—Ä—ã–µ –æ—Ç–≤–µ—Ç—ã (100ms –¥–ª—è Groq!)
    ‚úÖ –ú–ï–¢–†–ò–ö–ò –î–õ–Ø –ö–ê–ñ–î–û–ì–û –ó–ê–ü–†–û–°–ê
    """
    
    context_history = context_history or []
    request_start_time = time.time()
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç
    context_str = build_context_for_prompt(context_history)
    system_prompt = build_dialogue_system_prompt()
    full_prompt = f"{system_prompt}\n\n{context_str}–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_message}"
    
    # ==================== –ü–û–ü–´–¢–ö–ê 1: GROQ ====================
    if GROQ_API_KEY:
        provider_start = time.time()
        logger.info(f"üîÑ Groq: –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç...")
        try:
            with httpx.Client() as client:
                response = client.post(
                    GROQ_API_URL,
                    headers={
                        "Authorization": f"Bearer {GROQ_API_KEY}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": GROQ_MODEL,
                        "messages": [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": f"{context_str}–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_message}"}
                        ],
                        "temperature": 0.7,
                        "max_tokens": 600,
                        "top_p": 0.95
                    },
                    timeout=timeout
                )
                
                provider_time = time.time() - provider_start
                logger.debug(f"üìä Groq HTTP: {response.status_code} ({provider_time:.2f}s)")
                
                if response.status_code == 200:
                    data = response.json()
                    if data.get("choices") and len(data["choices"]) > 0:
                        ai_response = data["choices"][0]["message"]["content"].strip()
                        if ai_response:
                            update_metrics("groq", True, provider_time)
                            logger.info(f"‚úÖ Groq OK ({len(ai_response)} —Å–∏–º–≤–æ–ª–æ–≤, {provider_time:.2f}s)")
                            return ai_response
                        else:
                            logger.warning(f"‚ö†Ô∏è  Groq: –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
                            update_metrics("groq", False, provider_time)
                    else:
                        logger.warning(f"‚ö†Ô∏è  Groq: –Ω–µ—Ç choices –≤ –æ—Ç–≤–µ—Ç–µ")
                        update_metrics("groq", False, provider_time)
                else:
                    logger.warning(f"‚ö†Ô∏è  Groq HTTP {response.status_code}")
                    update_metrics("groq", False, provider_time)
                    
        except httpx.TimeoutException:
            provider_time = time.time() - provider_start
            logger.warning(f"‚è±Ô∏è  Groq: Timeout ({provider_time:.2f}s)")
            update_metrics("groq", False, provider_time, error_type="timeout")
        except Exception as e:
            provider_time = time.time() - provider_start
            logger.warning(f"‚ùå Groq –æ—à–∏–±–∫–∞: {type(e).__name__}: {str(e)[:100]}")
            update_metrics("groq", False, provider_time)
    else:
        logger.warning("‚ö†Ô∏è  GROQ_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    
    # ==================== –ü–û–ü–´–¢–ö–ê 2: MISTRAL ====================
    if MISTRAL_API_KEY and MISTRAL_API_KEY != "–ó–ê–ú–ï–ù–ò_–ù–ê_–ö–õ–Æ–ß_–ò–ó_MISTRAL":
        provider_start = time.time()
        logger.info(f"üîÑ Mistral: –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç (fallback 1)...")
        try:
            with httpx.Client() as client:
                response = client.post(
                    MISTRAL_API_URL,
                    headers={
                        "Authorization": f"Bearer {MISTRAL_API_KEY}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": MISTRAL_MODEL,
                        "messages": [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": f"{context_str}–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_message}"}
                        ],
                        "temperature": 0.7,
                        "max_tokens": 600,
                        "top_p": 0.95
                    },
                    timeout=timeout
                )
                
                provider_time = time.time() - provider_start
                logger.debug(f"üìä Mistral HTTP: {response.status_code}")
                
                if response.status_code == 200:
                    data = response.json()
                    if data.get("choices") and len(data["choices"]) > 0:
                        ai_response = data["choices"][0]["message"]["content"].strip()
                        if ai_response:
                            update_metrics("mistral", True, provider_time)
                            logger.info(f"‚úÖ Mistral OK ({len(ai_response)} —Å–∏–º–≤–æ–ª–æ–≤, {provider_time:.2f}s)")
                            return ai_response
                        else:
                            logger.warning(f"‚ö†Ô∏è  Mistral: –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
                            update_metrics("mistral", False, provider_time)
                else:
                    logger.warning(f"‚ö†Ô∏è  Mistral HTTP {response.status_code}")
                    update_metrics("mistral", False, provider_time)
                    
        except httpx.TimeoutException:
            provider_time = time.time() - provider_start
            logger.warning(f"‚è±Ô∏è  Mistral: Timeout")
            update_metrics("mistral", False, provider_time, error_type="timeout")
        except Exception as e:
            provider_time = time.time() - provider_start
            logger.warning(f"‚ùå Mistral –æ—à–∏–±–∫–∞: {type(e).__name__}: {str(e)[:100]}")
            update_metrics("mistral", False, provider_time)
    else:
        logger.debug("‚è≠Ô∏è  Mistral: –ü—Ä–æ–ø—É—â–µ–Ω (–∫–ª—é—á –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)")
    
    # ==================== –ü–û–ü–´–¢–ö–ê 3: GEMINI ====================
    if GEMINI_API_KEY:
        provider_start = time.time()
        logger.info(f"üîÑ Gemini: –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç (fallback 2)...")
        try:
            url = f"{GEMINI_API_BASE}/{GEMINI_MODEL}:generateContent?key={GEMINI_API_KEY}"
            
            with httpx.Client() as client:
                response = client.post(
                    url,
                    json={
                        "contents": [{
                            "parts": [{
                                "text": full_prompt
                            }]
                        }],
                        "generationConfig": {
                            "temperature": 0.7,
                            "maxOutputTokens": 200,
                            "topP": 0.95
                        }
                    },
                    timeout=timeout
                )
                
                provider_time = time.time() - provider_start
                logger.debug(f"üìä Gemini HTTP: {response.status_code}")
                
                if response.status_code == 200:
                    data = response.json()
                    candidates = data.get("candidates", [])
                    if candidates and candidates[0].get("content", {}).get("parts"):
                        ai_response = candidates[0]["content"]["parts"][0].get("text", "").strip()
                        if ai_response:
                            update_metrics("gemini", True, provider_time)
                            logger.info(f"‚úÖ Gemini OK ({len(ai_response)} —Å–∏–º–≤–æ–ª–æ–≤, {provider_time:.2f}s)")
                            return ai_response
                        else:
                            logger.warning(f"‚ö†Ô∏è  Gemini: –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
                            update_metrics("gemini", False, provider_time)
                else:
                    logger.warning(f"‚ö†Ô∏è  Gemini HTTP {response.status_code}")
                    update_metrics("gemini", False, provider_time)
                    
        except httpx.TimeoutException:
            provider_time = time.time() - provider_start
            logger.warning(f"‚è±Ô∏è  Gemini: Timeout")
            update_metrics("gemini", False, provider_time, error_type="timeout")
        except Exception as e:
            provider_time = time.time() - provider_start
            logger.warning(f"‚ùå Gemini –æ—à–∏–±–∫–∞: {type(e).__name__}: {str(e)[:100]}")
            update_metrics("gemini", False, provider_time)
    else:
        logger.debug("‚è≠Ô∏è  Gemini: –ü—Ä–æ–ø—É—â–µ–Ω (–∫–ª—é—á –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)")
    
    # ==================== –í–°–ï –ü–†–û–í–ê–ô–î–ï–†–´ –ù–ï–î–û–°–¢–£–ü–ù–´ ====================
    logger.error(f"‚ùå –í–°–ï –ü–†–û–í–ê–ô–î–ï–†–´ –ù–ï–î–û–°–¢–£–ü–ù–´!")
    logger.error(f"   Groq: {'‚úÖ' if GROQ_API_KEY else '‚ùå'}")
    logger.error(f"   Mistral: {'‚úÖ' if MISTRAL_API_KEY and MISTRAL_API_KEY != '–ó–ê–ú–ï–ù–ò_–ù–ê_–ö–õ–Æ–ß_–ò–ó_MISTRAL' else '‚ùå'}")
    logger.error(f"   Gemini: {'‚úÖ' if GEMINI_API_KEY else '‚ùå'}")
    return None


# ==================== –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï ====================

if __name__ == "__main__":
    import sys
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(levelname)s: %(message)s'
    )
    
    print("\n" + "="*70)
    print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï AI DIALOGUE v0.23")
    print("="*70 + "\n")
    
    tests = [
        ("–ß—Ç–æ —Ç–∞–∫–æ–µ Bitcoin?", []),
        ("–ü–æ—á–µ–º—É?", [{"type": "bot", "content": "Bitcoin —ç—Ç–æ –≤–∞–ª—é—Ç–∞"}]),
        ("–ü—Ä–∏–≤–µ—Ç!", []),
    ]
    
    for msg, ctx in tests:
        print(f"üìù –¢–µ—Å—Ç: '{msg}'")
        response = get_ai_response_sync(msg, ctx)
        if response:
            print(f"‚úÖ –û—Ç–≤–µ—Ç: {response[:80]}...\n")
        else:
            print(f"‚ùå –ù–µ—Ç –æ—Ç–≤–µ—Ç–∞\n")
    
    print("="*70 + "\n")
