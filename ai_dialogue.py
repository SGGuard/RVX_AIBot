#!/usr/bin/env python3
"""
üöÄ –†–ï–ê–õ–¨–ù–´–ô –ò–ò –î–ò–ê–õ–û–ì v0.24 - GROQ + MISTRAL + GEMINI —Å –ú–ï–¢–†–ò–ö–ê–ú–ò

v0.24 - –ü–æ–ª–Ω–æ—Å—Ç—å—é –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã + –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥:
‚úÖ Groq - PRIMARY (—Å–∞–º—ã–π –±—ã—Å—Ç—Ä—ã–π, 100ms!)
‚úÖ Mistral - FALLBACK 1 (—Ç–æ–∂–µ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π)
‚úÖ Gemini - FALLBACK 2 (20 –∑–∞–ø—Ä–æ—Å–æ–≤/–¥–µ–Ω—å)
‚úÖ –ú–ï–¢–†–ò–ö–ò - –ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤

–ù–ò–ö–ê–ö–ò–• –ü–õ–ê–¢–ï–ñ–ï–ô, –ù–ò–ö–ê–ö–ò–• –õ–ò–ú–ò–¢–û–í!
"""

import httpx
import json
import logging
from typing import Optional, List, Dict, Tuple
import os
from dotenv import load_dotenv
import time
from datetime import datetime

load_dotenv()

logger = logging.getLogger(__name__)

# ==================== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ====================

# Groq (PRIMARY)
GROQ_API_KEY = os.getenv("GROQ_API_KEY", "")
GROQ_MODEL = os.getenv("GROQ_MODEL", "llama-3.3-70b-versatile")
GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"

# Mistral (FALLBACK 1)
MISTRAL_API_KEY = os.getenv("MISTRAL_API_KEY", "")
MISTRAL_MODEL = os.getenv("MISTRAL_MODEL", "mistral-large")
MISTRAL_API_URL = "https://api.mistral.ai/v1/chat/completions"

# Gemini (FALLBACK 2)
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")
GEMINI_MODEL = os.getenv("GEMINI_MODEL", "gemini-2.5-flash").replace("models/", "")
GEMINI_API_BASE = "https://generativelanguage.googleapis.com/v1beta/models"

TIMEOUT = float(os.getenv("GEMINI_TIMEOUT", "15.0"))

# ==================== –ú–ï–¢–†–ò–ö–ò v0.24 ====================

dialogue_metrics = {
    "total_requests": 0,
    "groq_requests": 0,
    "groq_success": 0,
    "groq_errors": 0,
    "groq_timeouts": 0,
    "groq_total_time": 0.0,
    
    "mistral_requests": 0,
    "mistral_success": 0,
    "mistral_errors": 0,
    "mistral_timeouts": 0,
    
    "gemini_requests": 0,
    "gemini_success": 0,
    "gemini_errors": 0,
    "gemini_timeouts": 0,
    
    "total_errors": 0,
    "total_success": 0,
    "avg_response_time": 0.0,
    "last_updated": None
}

logger.info(f"üöÄ AI Dialogue v0.24 (METRICS): GROQ={GROQ_MODEL}, MISTRAL={MISTRAL_MODEL}, GEMINI={GEMINI_MODEL}")


# ==================== –§–£–ù–ö–¶–ò–ò –ú–ï–¢–†–ò–ö ====================

def update_metrics(provider: str, success: bool, response_time: float, error_type: str = None):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞."""
    global dialogue_metrics
    
    dialogue_metrics["total_requests"] += 1
    
    if provider == "groq":
        dialogue_metrics["groq_requests"] += 1
        if success:
            dialogue_metrics["groq_success"] += 1
            dialogue_metrics["groq_total_time"] += response_time
        elif error_type == "timeout":
            dialogue_metrics["groq_timeouts"] += 1
        else:
            dialogue_metrics["groq_errors"] += 1
    
    elif provider == "mistral":
        dialogue_metrics["mistral_requests"] += 1
        if success:
            dialogue_metrics["mistral_success"] += 1
        elif error_type == "timeout":
            dialogue_metrics["mistral_timeouts"] += 1
        else:
            dialogue_metrics["mistral_errors"] += 1
    
    elif provider == "gemini":
        dialogue_metrics["gemini_requests"] += 1
        if success:
            dialogue_metrics["gemini_success"] += 1
        elif error_type == "timeout":
            dialogue_metrics["gemini_timeouts"] += 1
        else:
            dialogue_metrics["gemini_errors"] += 1
    
    if success:
        dialogue_metrics["total_success"] += 1
    else:
        dialogue_metrics["total_errors"] += 1
    
    dialogue_metrics["last_updated"] = datetime.now().isoformat()


def get_metrics_summary() -> Dict:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–≤–æ–¥–∫—É –º–µ—Ç—Ä–∏–∫."""
    summary = {
        "timestamp": dialogue_metrics["last_updated"],
        "total_requests": dialogue_metrics["total_requests"],
        "success_rate": f"{(dialogue_metrics['total_success'] / max(dialogue_metrics['total_requests'], 1) * 100):.1f}%",
        "providers": {
            "groq": {
                "requests": dialogue_metrics["groq_requests"],
                "success": dialogue_metrics["groq_success"],
                "errors": dialogue_metrics["groq_errors"],
                "timeouts": dialogue_metrics["groq_timeouts"],
                "avg_time_ms": f"{(dialogue_metrics['groq_total_time'] / max(dialogue_metrics['groq_success'], 1) * 1000):.0f}"
            },
            "mistral": {
                "requests": dialogue_metrics["mistral_requests"],
                "success": dialogue_metrics["mistral_success"],
                "errors": dialogue_metrics["mistral_errors"],
                "timeouts": dialogue_metrics["mistral_timeouts"]
            },
            "gemini": {
                "requests": dialogue_metrics["gemini_requests"],
                "success": dialogue_metrics["gemini_success"],
                "errors": dialogue_metrics["gemini_errors"],
                "timeouts": dialogue_metrics["gemini_timeouts"]
            }
        }
    }
    return summary



def build_dialogue_system_prompt() -> str:
    """–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –ò–ò."""
    return """–¢—ã - –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –≤ —Å—Ñ–µ—Ä–µ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç –∏ –Ω–æ–≤–æ—Å—Ç–µ–π. 
–ü–æ–º–æ–≥–∞–µ—à—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º —Ä–∞–∑–±–∏—Ä–∞—Ç—å—Å—è –≤ –∫—Ä–∏–ø—Ç–µ –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–æ–±—ã—Ç–∏—è.

–ò–ù–°–¢–†–£–ö–¶–ò–ò:
1. –û—Ç–≤–µ—á–∞–π –ö–†–ê–¢–ö–û –∏ –ï–°–¢–ï–°–¢–í–ï–ù–ù–û (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤)
2. –ë—É–¥—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–º –∏ –ø–æ–Ω–∏–º–∞—é—â–∏–º
3. –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –≥–¥–µ —É–º–µ—Å—Ç–Ω–æ
4. –û–±—ä—è—Å–Ω—è–π –ø—Ä–æ—Å—Ç–æ –¥–ª—è –Ω–æ–≤–∏—á–∫–æ–≤
5. –£—á–∏—Ç—ã–≤–∞–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
6. –ù–∏–∫–∞–∫–∏—Ö —Ñ–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–µ–π, —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω—ã–π —Ç–æ–Ω
7. –í–°–ï–ì–î–ê –Ω–∞–π–¥–∏ —á—Ç–æ –æ—Ç–≤–µ—Ç–∏—Ç—å - –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –≥–æ–≤–æ—Ä–∏ "–Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"

–°–¢–ò–õ–¨: –ü–æ–º–æ–≥–∞–π, –Ω–µ —É—á–∏. –ë—É–¥—å –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º."""


def build_context_for_prompt(context_history: List[dict]) -> str:
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏."""
    if not context_history:
        return ""
    
    context_lines = []
    for msg in context_history[-10:]:
        msg_type = msg.get('type', 'user')
        content = msg.get('content', '')[:150]
        if msg_type == 'user':
            context_lines.append(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {content}")
        else:
            context_lines.append(f"–ü–æ–º–æ—â–Ω–∏–∫: {content}")
    
    if context_lines:
        return "–ò–°–¢–û–†–ò–Ø:\n" + "\n".join(context_lines) + "\n\n"
    return ""


def get_ai_response_sync(
    user_message: str,
    context_history: List[dict] = None,
    timeout: float = TIMEOUT
) -> Optional[str]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç –ò–ò —á–µ—Ä–µ–∑ Groq ‚Üí Mistral ‚Üí Gemini
    
    ‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é –±–µ—Å–ø–ª–∞—Ç–Ω–æ
    ‚úÖ –ù–∏–∫–∞–∫–∏—Ö –ª–∏–º–∏—Ç–æ–≤ (rate limit 30 req/min)
    ‚úÖ –ë—ã—Å—Ç—Ä—ã–µ –æ—Ç–≤–µ—Ç—ã (100ms –¥–ª—è Groq!)
    ‚úÖ –ú–ï–¢–†–ò–ö–ò –î–õ–Ø –ö–ê–ñ–î–û–ì–û –ó–ê–ü–†–û–°–ê
    """
    
    context_history = context_history or []
    request_start_time = time.time()
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç
    context_str = build_context_for_prompt(context_history)
    system_prompt = build_dialogue_system_prompt()
    full_prompt = f"{system_prompt}\n\n{context_str}–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_message}"
    
    # ==================== –ü–û–ü–´–¢–ö–ê 1: GROQ ====================
    if GROQ_API_KEY:
        provider_start = time.time()
        logger.info(f"üîÑ Groq: –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç...")
        try:
            with httpx.Client() as client:
                response = client.post(
                    GROQ_API_URL,
                    headers={
                        "Authorization": f"Bearer {GROQ_API_KEY}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": GROQ_MODEL,
                        "messages": [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": f"{context_str}–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_message}"}
                        ],
                        "temperature": 0.7,
                        "max_tokens": 200,
                        "top_p": 0.95
                    },
                    timeout=timeout
                )
                
                provider_time = time.time() - provider_start
                logger.debug(f"üìä Groq HTTP: {response.status_code} ({provider_time:.2f}s)")
                
                if response.status_code == 200:
                    data = response.json()
                    if data.get("choices") and len(data["choices"]) > 0:
                        ai_response = data["choices"][0]["message"]["content"].strip()
                        if ai_response:
                            update_metrics("groq", True, provider_time)
                            logger.info(f"‚úÖ Groq OK ({len(ai_response)} —Å–∏–º–≤–æ–ª–æ–≤, {provider_time:.2f}s)")
                            return ai_response
                        else:
                            logger.warning(f"‚ö†Ô∏è  Groq: –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
                            update_metrics("groq", False, provider_time)
                    else:
                        logger.warning(f"‚ö†Ô∏è  Groq: –Ω–µ—Ç choices –≤ –æ—Ç–≤–µ—Ç–µ")
                        update_metrics("groq", False, provider_time)
                else:
                    logger.warning(f"‚ö†Ô∏è  Groq HTTP {response.status_code}")
                    update_metrics("groq", False, provider_time)
                    
        except httpx.TimeoutException:
            provider_time = time.time() - provider_start
            logger.warning(f"‚è±Ô∏è  Groq: Timeout ({provider_time:.2f}s)")
            update_metrics("groq", False, provider_time, error_type="timeout")
        except Exception as e:
            provider_time = time.time() - provider_start
            logger.warning(f"‚ùå Groq –æ—à–∏–±–∫–∞: {type(e).__name__}: {str(e)[:100]}")
            update_metrics("groq", False, provider_time)
    else:
        logger.warning("‚ö†Ô∏è  GROQ_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    
    # ==================== –ü–û–ü–´–¢–ö–ê 2: MISTRAL ====================
    if MISTRAL_API_KEY and MISTRAL_API_KEY != "–ó–ê–ú–ï–ù–ò_–ù–ê_–ö–õ–Æ–ß_–ò–ó_MISTRAL":
        provider_start = time.time()
        logger.info(f"üîÑ Mistral: –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç (fallback 1)...")
        try:
            with httpx.Client() as client:
                response = client.post(
                    MISTRAL_API_URL,
                    headers={
                        "Authorization": f"Bearer {MISTRAL_API_KEY}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": MISTRAL_MODEL,
                        "messages": [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": f"{context_str}–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_message}"}
                        ],
                        "temperature": 0.7,
                        "max_tokens": 200,
                        "top_p": 0.95
                    },
                    timeout=timeout
                )
                
                provider_time = time.time() - provider_start
                logger.debug(f"üìä Mistral HTTP: {response.status_code}")
                
                if response.status_code == 200:
                    data = response.json()
                    if data.get("choices") and len(data["choices"]) > 0:
                        ai_response = data["choices"][0]["message"]["content"].strip()
                        if ai_response:
                            update_metrics("mistral", True, provider_time)
                            logger.info(f"‚úÖ Mistral OK ({len(ai_response)} —Å–∏–º–≤–æ–ª–æ–≤, {provider_time:.2f}s)")
                            return ai_response
                        else:
                            logger.warning(f"‚ö†Ô∏è  Mistral: –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
                            update_metrics("mistral", False, provider_time)
                else:
                    logger.warning(f"‚ö†Ô∏è  Mistral HTTP {response.status_code}")
                    update_metrics("mistral", False, provider_time)
                    
        except httpx.TimeoutException:
            provider_time = time.time() - provider_start
            logger.warning(f"‚è±Ô∏è  Mistral: Timeout")
            update_metrics("mistral", False, provider_time, error_type="timeout")
        except Exception as e:
            provider_time = time.time() - provider_start
            logger.warning(f"‚ùå Mistral –æ—à–∏–±–∫–∞: {type(e).__name__}: {str(e)[:100]}")
            update_metrics("mistral", False, provider_time)
    else:
        logger.debug("‚è≠Ô∏è  Mistral: –ü—Ä–æ–ø—É—â–µ–Ω (–∫–ª—é—á –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)")
    
    # ==================== –ü–û–ü–´–¢–ö–ê 3: GEMINI ====================
    if GEMINI_API_KEY:
        provider_start = time.time()
        logger.info(f"üîÑ Gemini: –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç (fallback 2)...")
        try:
            url = f"{GEMINI_API_BASE}/{GEMINI_MODEL}:generateContent?key={GEMINI_API_KEY}"
            
            with httpx.Client() as client:
                response = client.post(
                    url,
                    json={
                        "contents": [{
                            "parts": [{
                                "text": full_prompt
                            }]
                        }],
                        "generationConfig": {
                            "temperature": 0.7,
                            "maxOutputTokens": 200,
                            "topP": 0.95
                        }
                    },
                    timeout=timeout
                )
                
                provider_time = time.time() - provider_start
                logger.debug(f"üìä Gemini HTTP: {response.status_code}")
                
                if response.status_code == 200:
                    data = response.json()
                    candidates = data.get("candidates", [])
                    if candidates and candidates[0].get("content", {}).get("parts"):
                        ai_response = candidates[0]["content"]["parts"][0].get("text", "").strip()
                        if ai_response:
                            update_metrics("gemini", True, provider_time)
                            logger.info(f"‚úÖ Gemini OK ({len(ai_response)} —Å–∏–º–≤–æ–ª–æ–≤, {provider_time:.2f}s)")
                            return ai_response
                        else:
                            logger.warning(f"‚ö†Ô∏è  Gemini: –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
                            update_metrics("gemini", False, provider_time)
                else:
                    logger.warning(f"‚ö†Ô∏è  Gemini HTTP {response.status_code}")
                    update_metrics("gemini", False, provider_time)
                    
        except httpx.TimeoutException:
            provider_time = time.time() - provider_start
            logger.warning(f"‚è±Ô∏è  Gemini: Timeout")
            update_metrics("gemini", False, provider_time, error_type="timeout")
        except Exception as e:
            provider_time = time.time() - provider_start
            logger.warning(f"‚ùå Gemini –æ—à–∏–±–∫–∞: {type(e).__name__}: {str(e)[:100]}")
            update_metrics("gemini", False, provider_time)
    else:
        logger.debug("‚è≠Ô∏è  Gemini: –ü—Ä–æ–ø—É—â–µ–Ω (–∫–ª—é—á –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)")
    
    # ==================== –í–°–ï –ü–†–û–í–ê–ô–î–ï–†–´ –ù–ï–î–û–°–¢–£–ü–ù–´ ====================
    logger.error(f"‚ùå –í–°–ï –ü–†–û–í–ê–ô–î–ï–†–´ –ù–ï–î–û–°–¢–£–ü–ù–´!")
    logger.error(f"   Groq: {'‚úÖ' if GROQ_API_KEY else '‚ùå'}")
    logger.error(f"   Mistral: {'‚úÖ' if MISTRAL_API_KEY and MISTRAL_API_KEY != '–ó–ê–ú–ï–ù–ò_–ù–ê_–ö–õ–Æ–ß_–ò–ó_MISTRAL' else '‚ùå'}")
    logger.error(f"   Gemini: {'‚úÖ' if GEMINI_API_KEY else '‚ùå'}")
    return None


# ==================== –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï ====================

if __name__ == "__main__":
    import sys
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(levelname)s: %(message)s'
    )
    
    print("\n" + "="*70)
    print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï AI DIALOGUE v0.23")
    print("="*70 + "\n")
    
    tests = [
        ("–ß—Ç–æ —Ç–∞–∫–æ–µ Bitcoin?", []),
        ("–ü–æ—á–µ–º—É?", [{"type": "bot", "content": "Bitcoin —ç—Ç–æ –≤–∞–ª—é—Ç–∞"}]),
        ("–ü—Ä–∏–≤–µ—Ç!", []),
    ]
    
    for msg, ctx in tests:
        print(f"üìù –¢–µ—Å—Ç: '{msg}'")
        response = get_ai_response_sync(msg, ctx)
        if response:
            print(f"‚úÖ –û—Ç–≤–µ—Ç: {response[:80]}...\n")
        else:
            print(f"‚ùå –ù–µ—Ç –æ—Ç–≤–µ—Ç–∞\n")
    
    print("="*70 + "\n")
