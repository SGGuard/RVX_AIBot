import os
import logging
import json
import re 
from typing import Optional
from contextlib import asynccontextmanager

from fastapi import FastAPI, HTTPException, Request
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field, validator
from dotenv import load_dotenv
from starlette.concurrency import run_in_threadpool 

from google import genai
from google.genai.errors import APIError

# --- 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ---
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger("RVX_API")

# --- 2. –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ ---
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
MAX_TEXT_LENGTH = int(os.getenv("MAX_TEXT_LENGTH", "4096"))
GEMINI_MODEL = os.getenv("GEMINI_MODEL", "models/gemini-2.5-flash")
GEMINI_TEMPERATURE = float(os.getenv("GEMINI_TEMPERATURE", "0.3"))
GEMINI_MAX_TOKENS = int(os.getenv("GEMINI_MAX_TOKENS", "1500"))

# --- 3. –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ ---
client: Optional[genai.Client] = None
request_counter = {"total": 0, "success": 0, "errors": 0}

# --- 4. Lifecycle management ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è."""
    global client
    
    # Startup
    logger.info("=" * 60)
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ RVX AI Backend API")
    logger.info("=" * 60)
    
    if not GEMINI_API_KEY:
        logger.critical("‚ùå GEMINI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env!")
    else:
        try:
            client = genai.Client(api_key=GEMINI_API_KEY)
            logger.info("‚úÖ –ö–ª–∏–µ–Ω—Ç Gemini –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Gemini: {e}")
            client = None
    
    logger.info("–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:")
    logger.info(f"  ‚Ä¢ MAX_TEXT_LENGTH: {MAX_TEXT_LENGTH}")
    logger.info(f"  ‚Ä¢ GEMINI_MODEL: {GEMINI_MODEL}")
    logger.info(f"  ‚Ä¢ TEMPERATURE: {GEMINI_TEMPERATURE}")
    logger.info(f"  ‚Ä¢ MAX_TOKENS: {GEMINI_MAX_TOKENS}")
    logger.info("=" * 60)
    
    yield
    
    # Shutdown
    logger.info("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ API")
    logger.info(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {request_counter['total']} –∑–∞–ø—Ä–æ—Å–æ–≤, "
                f"{request_counter['success']} —É—Å–ø–µ—à–Ω—ã—Ö, {request_counter['errors']} –æ—à–∏–±–æ–∫")

app = FastAPI(
    title="RVX AI Backend",
    version="2.2.0",
    description="API –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫—Ä–∏–ø—Ç–æ–Ω–æ–≤–æ—Å—Ç–µ–π",
    lifespan=lifespan
)

# --- 5. –£—Ç–∏–ª–∏—Ç—ã ---

def clean_text(text: str) -> str:
    """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç markdown –∏ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤."""
    if not text:
        return ""
    
    # –£–±–∏—Ä–∞–µ–º markdown
    text = text.replace('**', '').replace('*', '')
    text = text.replace('__', '').replace('_', '')
    text = text.replace('~~', '')
    
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    text = ' '.join(text.split())
    
    return text.strip()

def extract_json_from_response(raw_text: str) -> Optional[dict]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ AI."""
    if not raw_text:
        return None
    
    # –û—á–∏—â–∞–µ–º –æ—Ç markdown –±–ª–æ–∫–æ–≤
    raw_text = re.sub(r'```json\s*', '', raw_text)
    raw_text = re.sub(r'```\s*', '', raw_text)
    
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: XML —Ç–µ–≥–∏
    xml_match = re.search(r'<json>(.*?)</json>', raw_text, re.DOTALL | re.IGNORECASE)
    if xml_match:
        try:
            return json.loads(xml_match.group(1).strip())
        except json.JSONDecodeError:
            pass
    
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –ü–æ–∏—Å–∫ {...}
    brace_match = re.search(r'\{.*\}', raw_text, re.DOTALL)
    if brace_match:
        try:
            return json.loads(brace_match.group(0))
        except json.JSONDecodeError:
            pass
    
    logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å JSON: {raw_text[:200]}...")
    return None

def validate_analysis(data: dict) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ—Ç–≤–µ—Ç–∞ AI."""
    if not isinstance(data, dict):
        return False
    
    if "summary_text" not in data or not isinstance(data["summary_text"], str):
        return False
    
    if "impact_points" not in data or not isinstance(data["impact_points"], list):
        return False
    
    if not data["impact_points"] or not all(isinstance(p, str) for p in data["impact_points"]):
        return False
    
    return True

def format_response(analysis: dict) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∞–Ω–∞–ª–∏–∑ –¥–ª—è Telegram."""
    summary = clean_text(analysis.get('summary_text', '–ù–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è'))
    
    emojis = ['üìâ', 'üìä', '‚ö°Ô∏è', 'üí∞', 'üéØ', 'üî•', 'üìà', '‚ö†Ô∏è']
    separator = "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
    
    result = f"{separator}\nüîç –°–£–¢–¨\n\n{summary}\n\n{separator}\nüí° –í–õ–ò–Ø–ù–ò–ï –ù–ê –ö–†–ò–ü–¢–£\n\n"
    
    for i, point in enumerate(analysis.get('impact_points', [])):
        if point.strip():
            clean_point = clean_text(point)
            emoji = emojis[i % len(emojis)]
            result += f"{emoji} {clean_point}\n\n"
    
    result += separator
    return result.strip()

# --- 6. –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö ---

class NewsPayload(BaseModel):
    """–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ."""
    text_content: str = Field(..., min_length=10, max_length=MAX_TEXT_LENGTH)
    
    @validator('text_content')
    def validate_text(cls, v):
        if not v.strip():
            raise ValueError("–¢–µ–∫—Å—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
        return v.strip()

class SimplifiedResponse(BaseModel):
    """–û—Ç–≤–µ—Ç API."""
    simplified_text: str

class HealthResponse(BaseModel):
    """Health check."""
    status: str
    gemini_available: bool
    requests_total: int
    requests_success: int
    requests_errors: int

# --- 7. Middleware ---

@app.middleware("http")
async def log_requests(request: Request, call_next):
    """–õ–æ–≥–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å—ã."""
    logger.info(f"üì® {request.method} {request.url.path}")
    request_counter["total"] += 1
    
    try:
        response = await call_next(request)
        return response
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        request_counter["errors"] += 1
        return JSONResponse(
            status_code=500,
            content={"simplified_text": "‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞"}
        )

# --- 8. –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã ---

@app.get("/")
async def root():
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± API."""
    return {
        "service": "RVX AI Backend",
        "version": "2.2.0",
        "status": "running",
        "endpoints": {
            "analyze": "/explain_news",
            "health": "/health"
        }
    }

@app.get("/health", response_model=HealthResponse)
async def health_check():
    """Health check."""
    return HealthResponse(
        status="healthy" if client else "degraded",
        gemini_available=client is not None,
        requests_total=request_counter["total"],
        requests_success=request_counter["success"],
        requests_errors=request_counter["errors"]
    )

@app.post("/explain_news", response_model=SimplifiedResponse)
async def explain_news(payload: NewsPayload):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫—Ä–∏–ø—Ç–æ–Ω–æ–≤–æ—Å—Ç—å."""
    if not client:
        logger.error("Gemini –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        request_counter["errors"] += 1
        raise HTTPException(503, "–°–µ—Ä–≤–∏—Å AI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
    
    news_text = payload.text_content
    logger.info(f"üì• –ê–Ω–∞–ª–∏–∑ ({len(news_text)} —Å–∏–º–≤–æ–ª–æ–≤)")
    
    # –ü—Ä–æ–º–ø—Ç –¥–ª—è AI
    system_prompt = (
        "–¢—ã ‚Äî –∫—Ä–∏–ø—Ç–æ–∞–Ω–∞–ª–∏—Ç–∏–∫ RVX. –û–±—ä—è—Å–Ω—è–π –Ω–æ–≤–æ—Å—Ç–∏ –ø—Ä–æ—Å—Ç–æ.\n\n"
        "–ü–†–ê–í–ò–õ–ê:\n"
        "- –û—Ç–≤–µ—á–∞–π JSON –≤ —Ç–µ–≥–∞—Ö <json></json>\n"
        "- –ë–ï–ó markdown (**, *, _)\n"
        "- –ë–ï–ó —ç–º–æ–¥–∑–∏\n\n"
        "–§–æ—Ä–º–∞—Ç:\n"
        '{"summary_text": "2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –æ —Å—É—Ç–∏", '
        '"impact_points": ["–ø—É–Ω–∫—Ç 1", "–ø—É–Ω–∫—Ç 2", "–ø—É–Ω–∫—Ç 3"]}\n\n'
        "–ü—Ä–∏–º–µ—Ä:\n"
        '{"summary_text": "Bitcoin –¥–æ—Å—Ç–∏–≥ –º–∞–∫—Å–∏–º—É–º–∞. –†–æ—Å—Ç —Å–≤—è–∑–∞–Ω —Å –∏–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º —Å–ø—Ä–æ—Å–æ–º.", '
        '"impact_points": ["–£—Å–∏–ª–µ–Ω–∏–µ –¥–æ–≤–µ—Ä–∏—è", "–í–æ–∑–º–æ–∂–Ω—ã–π —Ä–æ—Å—Ç –∞–ª—å—Ç–∫–æ–∏–Ω–æ–≤"]}'
    )
    
    user_prompt = f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π:\n\n{news_text}"
    
    try:
        # –í—ã–∑–æ–≤ Gemini
        def sync_call():
            return client.models.generate_content(
                model=GEMINI_MODEL,
                contents=[user_prompt],
                config={
                    "system_instruction": system_prompt,
                    "temperature": GEMINI_TEMPERATURE,
                    "max_output_tokens": GEMINI_MAX_TOKENS
                }
            )
        
        logger.info("ü§ñ –ó–∞–ø—Ä–æ—Å –∫ Gemini...")
        response = await run_in_threadpool(sync_call)
        raw_text = response.text
        
        if not raw_text:
            logger.warning("‚ö†Ô∏è –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
            request_counter["errors"] += 1
            return SimplifiedResponse(
                simplified_text="‚ö†Ô∏è AI –Ω–µ —Å–º–æ–≥ –æ—Ç–≤–µ—Ç–∏—Ç—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥—É—é –Ω–æ–≤–æ—Å—Ç—å."
            )
        
        logger.info(f"üì§ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω ({len(raw_text)} —Å–∏–º–≤–æ–ª–æ–≤)")
        
        # –ü–∞—Ä—Å–∏–Ω–≥
        data = extract_json_from_response(raw_text)
        
        if not data or not validate_analysis(data):
            logger.error("‚ùå –ù–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON")
            request_counter["errors"] += 1
            return SimplifiedResponse(
                simplified_text="‚ùå AI –≤–µ—Ä–Ω—É–ª –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç."
            )
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        formatted = format_response(data)
        
        logger.info("‚úÖ –£—Å–ø–µ—Ö")
        request_counter["success"] += 1
        
        return SimplifiedResponse(simplified_text=formatted)
    
    except APIError as e:
        logger.error(f"‚ùå Gemini API: {e}")
        request_counter["errors"] += 1
        return SimplifiedResponse(
            simplified_text="‚ùå –°–µ—Ä–≤–∏—Å AI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É."
        )
    
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞: {e}", exc_info=True)
        request_counter["errors"] += 1
        return SimplifiedResponse(
            simplified_text="‚ùå –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞."
        )

# --- 9. –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –æ—à–∏–±–æ–∫ ---

@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    """HTTP –æ—à–∏–±–∫–∏."""
    return JSONResponse(
        status_code=exc.status_code,
        content={"simplified_text": f"‚ùå {exc.detail}"}
    )

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    """–û–±—â–∏–µ –æ—à–∏–±–∫–∏."""
    logger.error(f"–ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {exc}", exc_info=True)
    request_counter["errors"] += 1
    return JSONResponse(
        status_code=500,
        content={"simplified_text": "‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞"}
    )

# --- 10. –ó–∞–ø—É—Å–∫ ---
if __name__ == "__main__":
    import uvicorn
    
    port = int(os.getenv("PORT", "8000"))
    logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ –Ω–∞ –ø–æ—Ä—Ç—É {port}")
    
    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=port,
        reload=True
    )