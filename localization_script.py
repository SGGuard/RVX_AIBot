#!/usr/bin/env python3
"""
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ª–æ–∫–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è bot.py
–≠—Ç–æ —Å–∫—Ä–∏–ø—Ç –ø–∞—Ä—Å–∏—Ç bot.py, –Ω–∞—Ö–æ–¥–∏—Ç –≤—Å–µ —Ä—É—Å—Å–∫–∏–µ —Å—Ç—Ä–æ–∫–∏ –≤ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞—Ö,
—Å–æ–∑–¥–∞–µ—Ç translation keys –∏ –∑–∞–º–µ–Ω—è–µ—Ç –∏—Ö –Ω–∞ –≤—ã–∑–æ–≤—ã get_text()
"""

import re
import json
from pathlib import Path
from typing import Dict, List, Tuple

# –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –≤ –∫–∞–≤—ã—á–∫–∞—Ö
RUSSIAN_TEXT_PATTERN = r'(["\'])([–∞-—è–ê-–Ø—ë–Å\d\s\-\.\,\!\?\:\;\(\)\/\@\#\$\%\&\*\+\=\~\`\\]+)\1'

class BotLocalizer:
    def __init__(self, bot_file: str, ru_locale: str, uk_locale: str):
        self.bot_file = Path(bot_file)
        self.ru_locale = Path(ru_locale)
        self.uk_locale = Path(uk_locale)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ª–æ–∫–∞–ª–∏
        with open(self.ru_locale) as f:
            self.ru_dict = json.load(f)
        with open(self.uk_locale) as f:
            self.uk_dict = json.load(f)
        
        # –ß–∏—Ç–∞–µ–º bot.py
        with open(self.bot_file) as f:
            self.bot_content = f.read()
        
        self.new_keys = {}
        self.replacements = {}
    
    def extract_russian_text(self) -> List[Tuple[str, str]]:
        """–ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ —Ä—É—Å—Å–∫–∏–µ —Å—Ç—Ä–æ–∫–∏ –≤ bot.py"""
        matches = []
        for match in re.finditer(RUSSIAN_TEXT_PATTERN, self.bot_content):
            quote_type = match.group(1)
            text = match.group(2)
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏
            if len(text) < 3:
                continue
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∂–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ (–Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å emoji)
            if text[0] in ['üéì', '‚úÖ', '‚ùå', 'üìö', 'üèÜ', 'üí¨', 'üìä', '‚öôÔ∏è', '‚¨ÖÔ∏è', 'üì¶', 'üéØ', 'üìã', '‚ö†Ô∏è', 'üåê']:
                continue
            
            matches.append((text, quote_type))
        
        return matches
    
    def generate_key(self, text: str, context: str = "") -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á –¥–ª—è —Ç–µ–∫—Å—Ç–∞"""
        # –£–¥–∞–ª—è–µ–º —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã –∏ emoji
        clean = re.sub(r'[^\w\s\-]', '', text.lower())
        clean = ' '.join(clean.split())[:50]  # –ú–∞–∫—Å 50 —Å–∏–º–≤–æ–ª–æ–≤
        clean = clean.replace(' ', '_')
        return f"general.{clean}"
    
    def process_handler_profile(self):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ profile"""
        print("Processing profile handler...")
        
        # –≠—Ç–æ —Ç—Ä–µ–±—É–µ—Ç —Ä—É—á–Ω–æ–π —Ä–∞–±–æ—Ç—ã, —Ç–∞–∫ —á—Ç–æ –ø–æ–∫–∞ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
        pass
    
    def generate_report(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ä—É—Å—Å–∫–∏—Ö —Å—Ç—Ä–æ–∫–∞—Ö"""
        print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(self.new_keys)} –Ω–æ–≤—ã—Ö –∫–ª—é—á–µ–π –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è")
        print(f"   –ü—Ä–∏–º–µ—Ä—ã: {list(self.new_keys.keys())[:5]}")

if __name__ == "__main__":
    print("üöÄ –ó–∞–ø—É—Å–∫ –ª–æ–∫–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ bot.py...")
    
    localizer = BotLocalizer(
        "bot.py",
        "locales/ru.json",
        "locales/uk.json"
    )
    
    russian_texts = localizer.extract_russian_text()
    print(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(russian_texts)} —Ä—É—Å—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤")
    
    # –í—ã–≤–æ–¥–∏–º –ø–µ—Ä–≤—ã–µ 10
    for i, (text, quote) in enumerate(russian_texts[:10]):
        key = localizer.generate_key(text)
        print(f"  {i+1}. [{key}] = {text[:60]}")
    
    print(f"\n‚ö†Ô∏è –°–õ–ò–®–ö–û–ú –ú–ù–û–ì–û –î–õ–Ø –ê–í–¢–û–ú–ê–¢–ò–ó–ê–¶–ò–ò!")
    print("–ù—É–∂–Ω–∞ —Ä—É—á–Ω–∞—è —Ä–∞–±–æ—Ç–∞ –∏–ª–∏ –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º")
